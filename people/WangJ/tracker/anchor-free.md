

---------------------------------------------------------------------SiamFC++---------------------------------------------------------------------------------

代码链接:https://github.com/megviidetection/video_analyst

原文链接:http://arxiv.org/pdf/1911.06188v4.pdf

Abstract: 在RPN++的基础上去除了anchor机制, 采用anchor-free的方法对目标尺寸直接进行回归

Details: 1. 去除anchor的先验信息, 网络输出相当于k=1的情况, 分类分支输出双通道分类图(目标,背景), 回归分支直接对目标的尺寸进行回归, 具体方式为逐像素回归四维向量(l,t,r,b), 四维向量表示坐标点距离目标框的上下左右距离. 分类图label(目标框内坐标点为1,其余为0), 回归分支label(每个坐标点对目标框计算l,t,r,b). 另外在分类分支增加一个输出centerness, 以max(l,r)/min(l,r)和max(t,b)/min(t,b)的乘积为label计算loss, 表示目标中心的置信度. 2. 在RPN++得到的特征图上加一个FCOS_head模块推理最终结果.

Test: 以class与centerness的结果乘积进行目标定位,取目标点的(l,t,r,b)确定目标框.


--------------------------------------------------------------------SiamCAR-----------------------------------------------------------------------------------

代码链接:https://github.com/ohhhyeahhh/SiamCAR

原文链接:https://arxiv.org/abs/1911.07241

Abstract: 与SiamFC++思路类似, 区别在于SiamFC++保留了RPN++的整体网络, 在网络末端增加了FCOS_head模块, 使用了googlenet作为backbone, 没有使用特征融合机制, 而SiamCAR将RPN++_head模块直接替换成FCOS_head, 同时将特征融合放在backbone网络之后, 减少了Head的参数量.

Test: 先以class分类图粗定位目标范围, 再结合centerness得到目标的精确位置.

--------------------------------------------------------------------SiamKPN-----------------------------------------------------------------------------------

代码链接:https://github.com/ZekuiQin/SiamKPN

原文链接:http://xxx.itp.ac.cn/pdf/2006.04078v1

Abstract: 同样是anchor-free的方法,loss与上述算法大同小异, 其次提出了适合级联的一种KPN头模块

Detail: 使用级联结构, 级联过程中label逐渐细化, 越往后label越精细, 每一级都融合了三层特征来预测.

---------------------------------------------------------------------SiamBAN----------------------------------------------------------------------------------

代码链接:https://github.com/hqucv/siamban

原文链接:http://xxx.itp.ac.cn/pdf/2003.06761v2.pdf

Abstract: 使用了一种基于目标框的椭圆形分类label

Detail: 1.以目标框中心点为焦点,w,h为轴长绘制椭圆, 椭圆内表示在目标框内. 2.去除了centerness分支.

---------------------------------------------------------------------Ocean------------------------------------------------------------------------------------

代码链接:https://github.com/researchmm/TracKit

原文链接:https://arxiv.org/pdf/2006.10721.pdf

Abstract: 提出了一种目标边界感知的采样模块,提升特征的鉴别能力

Detail: 1.特征融合部分, 不使用res50的三种尺寸的特征, 仅用最后一层特征分别经过三个平行的扩张卷积层再进行互相关操作, 最后将得到的三个特征图累加. 2. 目标边界感知模块, 通过用回归特征图推理的regression map中的dx,dy,w,h,对步骤1得到的分类特征图进行采样,再通过一层卷积预测classification map p1. 用重采样前的分类特征图推理得到p2. p1+p2作为最终分类图. 3. p1的loss是最大化推理框与目标框的IOU, p2的loss是分类交叉熵.
